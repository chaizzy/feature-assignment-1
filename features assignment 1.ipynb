{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84ece3a8-f5e6-42c9-84eb-b0c9c5509dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 1 :\n",
    "# Filter method\n",
    "# The Filter method in feature selection is a technique used to identify and \n",
    "#   select relevant features from a dataset based on their individual statistical properties.\n",
    "# It operates independently of any machine learning algorithm and aims to rank or score features based on their correlation or \n",
    "#   statistical significance with the target variable\n",
    "\n",
    "# Working\n",
    "# 1.Data Preparation: The dataset is preprocessed and prepared by handling missing values, encoding categorical variables, and normalizing or standardizing numerical features.\n",
    "# 2.Feature Ranking: Each feature is evaluated individually using statistical measures such as correlation, chi-square, information gain, or variance threshold.\n",
    "# 3.Feature Selection: A threshold or a fixed number of top-ranked features are selected based on the predefined criteria\n",
    "# 4.Model Training: The selected features are used as input for a machine learning model to build predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99ad575d-60ed-42c3-b854-615e69f2be4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 2 :\n",
    "# Wrapper method\n",
    "# The Wrapper method is a feature selection technique that uses a specific machine learning model as a \"wrapper\" to evaluate and \n",
    "#   select subsets of features based on their performance in the model.\n",
    "\n",
    "#  Wrapper method in feature selection differs from the Filter method in that it incorporates the machine learning algorithm itself as part of the feature selection process. \n",
    "#  Instead of relying solely on the statistical properties of individual features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b4adffb-946b-4550-b145-a2c2eba233e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 3 :\n",
    "# Embedded method \n",
    "# Embedded feature selection methods integrate the feature selection process directly into the training of the machine learning algorithm\n",
    "# These methods aim to select the most relevant features while simultaneously building the model\n",
    "\n",
    "# Techniques\n",
    "# 1.L1 Regularization (Lasso\n",
    "# 2.Tree-based Feature Importance\n",
    "# 3.Recursive Feature Elimination (RFE)\n",
    "# 4.Sequential Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8afdc1ca-23d0-4e18-9175-3d1bcbea239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 4 :\n",
    "# Drawbacks of Filter method\n",
    "# 1.Independence Assumption:The Filter method evaluates features individually based on their statistical properties, \n",
    "#       such as correlation or information gain, without considering the interactions or dependencies between features\n",
    "# 2.limited Evaluation Criterion: The Filter method relies solely on statistical measures to rank or score features, \n",
    "#        such as correlation coefficients or test statistics\n",
    "# 3.Ignoring the Target Variable: The Filter method considers the relationship between individual features and \n",
    "#        the target variable but does not take into account the specific requirements of the predictive task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ece4a27-d863-4a61-8eab-60b2e73ff09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 5:\n",
    "# situations in which we use filter method\n",
    "# 1.Large Datasets: The Filter method is computationally efficient and can handle large datasets with a high number of features. \n",
    "# 2.Exploratory Data Analysis: In exploratory data analysis tasks, the primary goal may be to gain insights into the relationships between features and the target variable. \n",
    "#   The Filter method can be a useful tool to identify potential associations and correlations between features and the target without the need for extensive modeling\n",
    "\n",
    "# situations in which we use wrapper method\n",
    "# 1.High-Dimensional Data: When dealing with high-dimensional data, where the number of features is much larger than the number of instances, \n",
    "#    the Wrapper method may face challenges due to the curse of dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a9a1250-3af9-44af-8063-1a1ef19c4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 6 :\n",
    "# 1.Understand the Problem: Gain a clear understanding of the customer churn prediction problem and the specific objectives of the predictive model.\n",
    "# 2.Data Preprocessing: Preprocess the dataset by handling missing values, encoding categorical variables, and normalizing or standardizing numerical features\n",
    "# 3.Identify the Target Variable: Determine the target variable, which in this case is customer churn.\n",
    "# 4.Select Statistical Measures: Choose appropriate statistical measures to evaluate the relevance of each feature to customer churn. \n",
    "# 5.Compute Feature Relevance: Calculate the chosen statistical measures for each feature in the dataset. This involves calculating correlations, chi-square values, \n",
    "#      or information gain scores between each feature and the target variable (customer churn)\n",
    "# 6.set a Threshold: Define a threshold or criterion to determine which features to include in the predictive model.\n",
    "# 7.Select Features: Select the features that meet the defined threshold or criterion.\n",
    "# 8.Model Training and Evaluation: Once the relevant features are identified, use them as input for training a predictive model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ce35ae4-3ad6-4f0d-81f5-14d5c542a653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 7 :\n",
    "# 1.Data Preprocessing: Start by preprocessing the dataset, including handling missing values, encoding categorical variables, and normalizing or standardizing numerical features.\n",
    "# 2.Select a Suitable Algorithm: Choose a machine learning algorithm that supports embedded feature selection or regularization techniques.  \n",
    "\n",
    "#3.Define the Target Variable: Determine the target variable for the prediction task, \n",
    "#    which in this case would be the outcome of the soccer match (e.g., win, loss, or draw). \n",
    "\n",
    "# 4.Feature Encoding: If your dataset contains categorical features, consider encoding them using suitable techniques such as \n",
    "#                     one-hot encoding or ordinal encoding to ensure compatibility with the chosen algorithm.\n",
    "\n",
    "# 5.Feature Selection with Embedded Methods:\n",
    "#  a. Regularization: Many embedded methods employ regularization techniques to control the model's complexity and handle feature selection. \n",
    "#  b. Feature Importance: Algorithms like random forests or GBM provide built-in feature importance measures.\n",
    "#  c. Coefficient Analysis: For models like logistic regression or linear SVM, you can analyze the magnitude and significance of the feature coefficients. \n",
    "# 6.Model Training and Evaluation: Train the selected machine learning algorithm on the dataset using the embedded feature selection technique. \n",
    "# 7.Iterative Process and Hyperparameter Tuning: Adjust the hyperparameters of the chosen algorithm, such as the regularization parameter or learning rate, \n",
    "#      to find the optimal balance between feature selection and model performance.\n",
    "# 8.Final Feature Subset: Once you have completed the iterations and evaluated the model's performance, finalize the feature subset selected by the embedded method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62bddf7-998b-4f15-b689-58850053b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 8:\n",
    "#1.Define the Problem: Clearly define the problem and the goal of your predictive model. In this case, it is to predict the price of a house based on its features.\n",
    "# 2.Data Preprocessing: Preprocess the dataset by handling missing values, encoding categorical variables, and normalizing or standardizing numerical features as needed. \n",
    "#          Ensure the dataset is in a suitable format for applying the Wrapper method.\n",
    "# 3.Choose a Subset of Features: Select a subset of features from your dataset to begin the feature selection process. \n",
    "# 4.Model Training and Evaluation: Train a machine learning model on the selected subset of features. \n",
    "\n",
    "# 5.Iterative Feature Selection: Implement an iterative feature selection process using the Wrapper method. There are two main approaches within the Wrapper method:\n",
    "# a. Forward Selection: Start with an empty set of features and iteratively add one feature at a time. Train the model with each additional feature and evaluate its performance. \n",
    "# b. Backward Elimination: Start with all features included and iteratively remove one feature at a time. Train the model without each feature and evaluate its performance.\n",
    "\n",
    "# 6.Performance Evaluation: At each step of the iterative feature selection process, assess the model's performance using the chosen metrics.\n",
    "# 7.Stopping Criterion: Determine a stopping criterion for the iterative process. This can be based on a desired level of model performance, \n",
    "#                       a specific number of features, or a predefined threshold for performance improvement. \n",
    "#  The criterion helps determine when to stop adding or removing features and finalize the feature set.\n",
    "\n",
    "# 8.Finalize the Feature Set: Once the stopping criterion is met, finalize the feature set that resulted in the best model performance. \n",
    "#  These selected features are considered the best set of features for predicting the house price based on the Wrapper method.\n",
    "# 9.Model Refinement: After finalizing the feature set, retrain the model using the selected features. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
